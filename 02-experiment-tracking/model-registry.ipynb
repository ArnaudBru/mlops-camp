{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLflow's Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlflow.client import MlflowClient\n",
    "\n",
    "\n",
    "MLFLOW_TRACKING_URI = \"sqlite:///mlflow.db\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the MLflow tracking server\n",
    "\n",
    "The `MlflowClient` object allows us to interact with...\n",
    "- an MLflow Tracking Server that creates and manages experiments and runs.\n",
    "- an MLflow Registry Server that creates and manages registered models and model versions. \n",
    "\n",
    "To instantiate it we need to pass a tracking URI and/or a registry URI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Experiment: artifact_location='/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/2', creation_time=1717084808062, experiment_id='2', last_update_time=1717084808062, lifecycle_stage='active', name='my-cool-experiment', tags={}>,\n",
       " <Experiment: artifact_location='/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1', creation_time=1716457758424, experiment_id='1', last_update_time=1716457758424, lifecycle_stage='active', name='nyc-taxi-experiment', tags={}>,\n",
       " <Experiment: artifact_location='/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/0', creation_time=1716457758404, experiment_id='0', last_update_time=1716457758404, lifecycle_stage='active', name='Default', tags={}>]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MlflowClient(tracking_uri=MLFLOW_TRACKING_URI)\n",
    "\n",
    "client.search_experiments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Experiment(name=my-cool-experiment) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(sqlite3.IntegrityError) UNIQUE constraint failed: experiments.name\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (?, ?, ?, ?, ?)]\n[parameters: ('my-cool-experiment', None, 'active', 1717086695322, 1717086695322)]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[1;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1821\u001b[0m         )\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mIntegrityError\u001b[0m: UNIQUE constraint failed: experiments.name",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mIntegrityError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/sqlalchemy_store.py:279\u001b[0m, in \u001b[0;36mSqlAlchemyStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m artifact_location:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;66;03m# this requires a double write. The first one to generate an autoincrement-ed ID\u001b[39;00m\n\u001b[0;32m--> 279\u001b[0m     eid \u001b[38;5;241m=\u001b[39m session\u001b[38;5;241m.\u001b[39mquery(SqlExperiment)\u001b[38;5;241m.\u001b[39mfilter_by(name\u001b[38;5;241m=\u001b[39mname)\u001b[38;5;241m.\u001b[39mfirst()\u001b[38;5;241m.\u001b[39mexperiment_id\n\u001b[1;32m    280\u001b[0m     experiment\u001b[38;5;241m.\u001b[39martifact_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_artifact_location(eid)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/query.py:2819\u001b[0m, in \u001b[0;36mQuery.first\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2818\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlimit(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39m_iter()\u001b[38;5;241m.\u001b[39mfirst()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/query.py:2903\u001b[0m, in \u001b[0;36mQuery._iter\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2902\u001b[0m statement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_statement_20()\n\u001b[0;32m-> 2903\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession\u001b[38;5;241m.\u001b[39mexecute(\n\u001b[1;32m   2904\u001b[0m     statement,\n\u001b[1;32m   2905\u001b[0m     params,\n\u001b[1;32m   2906\u001b[0m     execution_options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_sa_orm_load_options\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_options},\n\u001b[1;32m   2907\u001b[0m )\n\u001b[1;32m   2909\u001b[0m \u001b[38;5;66;03m# legacy: automatically set scalars, unique\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/session.py:1660\u001b[0m, in \u001b[0;36mSession.execute\u001b[0;34m(self, statement, params, execution_options, bind_arguments, _parent_execute_state, _add_event, **kw)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compile_state_cls \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1657\u001b[0m     (\n\u001b[1;32m   1658\u001b[0m         statement,\n\u001b[1;32m   1659\u001b[0m         execution_options,\n\u001b[0;32m-> 1660\u001b[0m     ) \u001b[38;5;241m=\u001b[39m compile_state_cls\u001b[38;5;241m.\u001b[39morm_pre_session_exec(\n\u001b[1;32m   1661\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1662\u001b[0m         statement,\n\u001b[1;32m   1663\u001b[0m         params,\n\u001b[1;32m   1664\u001b[0m         execution_options,\n\u001b[1;32m   1665\u001b[0m         bind_arguments,\n\u001b[1;32m   1666\u001b[0m         _parent_execute_state \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1667\u001b[0m     )\n\u001b[1;32m   1668\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/context.py:319\u001b[0m, in \u001b[0;36mORMCompileState.orm_pre_session_exec\u001b[0;34m(cls, session, statement, params, execution_options, bind_arguments, is_reentrant_invoke)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_options\u001b[38;5;241m.\u001b[39m_autoflush:\n\u001b[0;32m--> 319\u001b[0m     session\u001b[38;5;241m.\u001b[39m_autoflush()\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m statement, execution_options\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2257\u001b[0m, in \u001b[0;36mSession._autoflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2252\u001b[0m e\u001b[38;5;241m.\u001b[39madd_detail(\n\u001b[1;32m   2253\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraised as a result of Query-invoked autoflush; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2254\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconsider using a session.no_autoflush block if this \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2255\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflush is occurring prematurely\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2256\u001b[0m )\n\u001b[0;32m-> 2257\u001b[0m util\u001b[38;5;241m.\u001b[39mraise_(e, with_traceback\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/session.py:2246\u001b[0m, in \u001b[0;36mSession._autoflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2245\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2246\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m   2247\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sa_exc\u001b[38;5;241m.\u001b[39mStatementError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   2248\u001b[0m     \u001b[38;5;66;03m# note we are reraising StatementError as opposed to\u001b[39;00m\n\u001b[1;32m   2249\u001b[0m     \u001b[38;5;66;03m# raising FlushError with \"chaining\" to remain compatible\u001b[39;00m\n\u001b[1;32m   2250\u001b[0m     \u001b[38;5;66;03m# with code that catches StatementError, IntegrityError,\u001b[39;00m\n\u001b[1;32m   2251\u001b[0m     \u001b[38;5;66;03m# etc.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/session.py:3383\u001b[0m, in \u001b[0;36mSession.flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3382\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flushing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 3383\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flush(objects)\n\u001b[1;32m   3384\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/session.py:3522\u001b[0m, in \u001b[0;36mSession._flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3521\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m-> 3522\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m util\u001b[38;5;241m.\u001b[39msafe_reraise():\n\u001b[1;32m   3523\u001b[0m         transaction\u001b[38;5;241m.\u001b[39mrollback(_capture_exception\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/langhelpers.py:70\u001b[0m, in \u001b[0;36msafe_reraise.__exit__\u001b[0;34m(self, type_, value, traceback)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwarn_only:\n\u001b[0;32m---> 70\u001b[0m         compat\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m     71\u001b[0m             exc_value,\n\u001b[1;32m     72\u001b[0m             with_traceback\u001b[38;5;241m=\u001b[39mexc_tb,\n\u001b[1;32m     73\u001b[0m         )\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/session.py:3483\u001b[0m, in \u001b[0;36mSession._flush\u001b[0;34m(self, objects)\u001b[0m\n\u001b[1;32m   3482\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3483\u001b[0m     flush_context\u001b[38;5;241m.\u001b[39mexecute()\n\u001b[1;32m   3484\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py:456\u001b[0m, in \u001b[0;36mUOWTransaction.execute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rec \u001b[38;5;129;01min\u001b[39;00m topological\u001b[38;5;241m.\u001b[39msort(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdependencies, postsort_actions):\n\u001b[0;32m--> 456\u001b[0m     rec\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/unitofwork.py:630\u001b[0m, in \u001b[0;36mSaveUpdateAll.execute\u001b[0;34m(self, uow)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;129m@util\u001b[39m\u001b[38;5;241m.\u001b[39mpreload_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlalchemy.orm.persistence\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, uow):\n\u001b[0;32m--> 630\u001b[0m     util\u001b[38;5;241m.\u001b[39mpreloaded\u001b[38;5;241m.\u001b[39morm_persistence\u001b[38;5;241m.\u001b[39msave_obj(\n\u001b[1;32m    631\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapper,\n\u001b[1;32m    632\u001b[0m         uow\u001b[38;5;241m.\u001b[39mstates_for_mapper_hierarchy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmapper, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m    633\u001b[0m         uow,\n\u001b[1;32m    634\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py:245\u001b[0m, in \u001b[0;36msave_obj\u001b[0;34m(base_mapper, states, uowtransaction, single)\u001b[0m\n\u001b[1;32m    237\u001b[0m     _emit_update_statements(\n\u001b[1;32m    238\u001b[0m         base_mapper,\n\u001b[1;32m    239\u001b[0m         uowtransaction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    242\u001b[0m         update,\n\u001b[1;32m    243\u001b[0m     )\n\u001b[0;32m--> 245\u001b[0m     _emit_insert_statements(\n\u001b[1;32m    246\u001b[0m         base_mapper,\n\u001b[1;32m    247\u001b[0m         uowtransaction,\n\u001b[1;32m    248\u001b[0m         mapper,\n\u001b[1;32m    249\u001b[0m         table,\n\u001b[1;32m    250\u001b[0m         insert,\n\u001b[1;32m    251\u001b[0m     )\n\u001b[1;32m    253\u001b[0m _finalize_insert_update_commands(\n\u001b[1;32m    254\u001b[0m     base_mapper,\n\u001b[1;32m    255\u001b[0m     uowtransaction,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    271\u001b[0m     ),\n\u001b[1;32m    272\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/orm/persistence.py:1238\u001b[0m, in \u001b[0;36m_emit_insert_statements\u001b[0;34m(base_mapper, uowtransaction, mapper, table, insert, bookkeeping)\u001b[0m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1238\u001b[0m     result \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39m_execute_20(\n\u001b[1;32m   1239\u001b[0m         statement,\n\u001b[1;32m   1240\u001b[0m         params,\n\u001b[1;32m   1241\u001b[0m         execution_options\u001b[38;5;241m=\u001b[39mexecution_options,\n\u001b[1;32m   1242\u001b[0m     )\n\u001b[1;32m   1244\u001b[0m primary_key \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39minserted_primary_key\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1631\u001b[0m, in \u001b[0;36mConnection._execute_20\u001b[0;34m(self, statement, parameters, execution_options)\u001b[0m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m meth(\u001b[38;5;28mself\u001b[39m, args_10style, kwargs_10style, execution_options)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/sql/elements.py:332\u001b[0m, in \u001b[0;36mClauseElement._execute_on_connection\u001b[0;34m(self, connection, multiparams, params, execution_options, _force)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _force \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msupports_execution:\n\u001b[0;32m--> 332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39m_execute_clauseelement(\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28mself\u001b[39m, multiparams, params, execution_options\n\u001b[1;32m    334\u001b[0m     )\n\u001b[1;32m    335\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1498\u001b[0m, in \u001b[0;36mConnection._execute_clauseelement\u001b[0;34m(self, elem, multiparams, params, execution_options)\u001b[0m\n\u001b[1;32m   1490\u001b[0m compiled_sql, extracted_params, cache_hit \u001b[38;5;241m=\u001b[39m elem\u001b[38;5;241m.\u001b[39m_compile_w_cache(\n\u001b[1;32m   1491\u001b[0m     dialect\u001b[38;5;241m=\u001b[39mdialect,\n\u001b[1;32m   1492\u001b[0m     compiled_cache\u001b[38;5;241m=\u001b[39mcompiled_cache,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1496\u001b[0m     linting\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mcompiler_linting \u001b[38;5;241m|\u001b[39m compiler\u001b[38;5;241m.\u001b[39mWARN_LINTING,\n\u001b[1;32m   1497\u001b[0m )\n\u001b[0;32m-> 1498\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_context(\n\u001b[1;32m   1499\u001b[0m     dialect,\n\u001b[1;32m   1500\u001b[0m     dialect\u001b[38;5;241m.\u001b[39mexecution_ctx_cls\u001b[38;5;241m.\u001b[39m_init_compiled,\n\u001b[1;32m   1501\u001b[0m     compiled_sql,\n\u001b[1;32m   1502\u001b[0m     distilled_params,\n\u001b[1;32m   1503\u001b[0m     execution_options,\n\u001b[1;32m   1504\u001b[0m     compiled_sql,\n\u001b[1;32m   1505\u001b[0m     distilled_params,\n\u001b[1;32m   1506\u001b[0m     elem,\n\u001b[1;32m   1507\u001b[0m     extracted_params,\n\u001b[1;32m   1508\u001b[0m     cache_hit\u001b[38;5;241m=\u001b[39mcache_hit,\n\u001b[1;32m   1509\u001b[0m )\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_events:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m-> 1862\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_dbapi_exception(\n\u001b[1;32m   1863\u001b[0m         e, statement, parameters, cursor, context\n\u001b[1;32m   1864\u001b[0m     )\n\u001b[1;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:2043\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   2042\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m should_wrap:\n\u001b[0;32m-> 2043\u001b[0m     util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[1;32m   2044\u001b[0m         sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[1;32m   2045\u001b[0m     )\n\u001b[1;32m   2046\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/util/compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[1;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[0;32m-> 1819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\u001b[38;5;241m.\u001b[39mdo_execute(\n\u001b[1;32m   1820\u001b[0m             cursor, statement, parameters, context\n\u001b[1;32m   1821\u001b[0m         )\n\u001b[1;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/sqlalchemy/engine/default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[0;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 732\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mexecute(statement, parameters)\n",
      "\u001b[0;31mIntegrityError\u001b[0m: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(sqlite3.IntegrityError) UNIQUE constraint failed: experiments.name\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (?, ?, ?, ?, ?)]\n[parameters: ('my-cool-experiment', None, 'active', 1717086695322, 1717086695322)]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m client\u001b[38;5;241m.\u001b[39mcreate_experiment(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy-cool-experiment\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/client.py:1258\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m   1206\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m   1207\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1208\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1209\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1210\u001b[0m     tags: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1211\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1212\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m   1213\u001b[0m \n\u001b[1;32m   1214\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \n\u001b[1;32m   1257\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1258\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tracking_client\u001b[38;5;241m.\u001b[39mcreate_experiment(name, artifact_location, tags)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/_tracking_service/client.py:499\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    485\u001b[0m \n\u001b[1;32m    486\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    497\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[0;32m--> 499\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstore\u001b[38;5;241m.\u001b[39mcreate_experiment(\n\u001b[1;32m    500\u001b[0m     name\u001b[38;5;241m=\u001b[39mname,\n\u001b[1;32m    501\u001b[0m     artifact_location\u001b[38;5;241m=\u001b[39martifact_location,\n\u001b[1;32m    502\u001b[0m     tags\u001b[38;5;241m=\u001b[39m[ExperimentTag(key, value) \u001b[38;5;28;01mfor\u001b[39;00m (key, value) \u001b[38;5;129;01min\u001b[39;00m tags\u001b[38;5;241m.\u001b[39mitems()] \u001b[38;5;28;01mif\u001b[39;00m tags \u001b[38;5;28;01melse\u001b[39;00m [],\n\u001b[1;32m    503\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/tracking/sqlalchemy_store.py:282\u001b[0m, in \u001b[0;36mSqlAlchemyStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    280\u001b[0m         experiment\u001b[38;5;241m.\u001b[39martifact_location \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_artifact_location(eid)\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sqlalchemy\u001b[38;5;241m.\u001b[39mexc\u001b[38;5;241m.\u001b[39mIntegrityError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment(name=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) already exists. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    284\u001b[0m         RESOURCE_ALREADY_EXISTS,\n\u001b[1;32m    285\u001b[0m     )\n\u001b[1;32m    287\u001b[0m session\u001b[38;5;241m.\u001b[39mflush()\n\u001b[1;32m    288\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(experiment\u001b[38;5;241m.\u001b[39mexperiment_id)\n",
      "\u001b[0;31mMlflowException\u001b[0m: Experiment(name=my-cool-experiment) already exists. Error: (raised as a result of Query-invoked autoflush; consider using a session.no_autoflush block if this flush is occurring prematurely)\n(sqlite3.IntegrityError) UNIQUE constraint failed: experiments.name\n[SQL: INSERT INTO experiments (name, artifact_location, lifecycle_stage, creation_time, last_update_time) VALUES (?, ?, ?, ?, ?)]\n[parameters: ('my-cool-experiment', None, 'active', 1717086695322, 1717086695322)]\n(Background on this error at: https://sqlalche.me/e/14/gkpj)"
     ]
    }
   ],
   "source": [
    "client.create_experiment(name=\"my-cool-experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the latest versions for the experiment with id `1`..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mlflow.entities import ViewType\n",
    "\n",
    "runs = client.search_runs(\n",
    "    experiment_ids='1',\n",
    "    filter_string=\"metrics.rmse < 7\",\n",
    "    run_view_type=ViewType.ACTIVE_ONLY,\n",
    "    max_results=5,\n",
    "    order_by=[\"metrics.rmse ASC\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run id: 7852b56e86ce44e0a8ac2cc920633a93, rmse: 6.3040\n",
      "run id: 98e69c3858ac4c79bd52a12055019e6e, rmse: 6.3063\n",
      "run id: bd82941d820a48df89e5fb53feed8d9b, rmse: 6.3146\n",
      "run id: d2aaacb925a14a8b9ca0f66a854ebb16, rmse: 6.3184\n",
      "run id: 51431eab5e1649bb94e35fa68c0c4a27, rmse: 6.3184\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(f\"run id: {run.info.run_id}, rmse: {run.data.metrics['rmse']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interacting with the Model Registry\n",
    "\n",
    "In this section We will use the `MlflowClient` instance to:\n",
    "\n",
    "1. Register a new version for the experiment `nyc-taxi-regressor`\n",
    "2. Retrieve the latests versions of the model `nyc-taxi-regressor` and check that a new version `3` was created.\n",
    "3. Transition the version `3` to \"Staging\" and adding annotations to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'nyc-taxi-regressor' already exists. Creating a new version of this model...\n",
      "Created version '7' of model 'nyc-taxi-regressor'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1717087053211, current_stage='None', description=None, last_updated_timestamp=1717087053211, name='nyc-taxi-regressor', run_id='d2aaacb925a14a8b9ca0f66a854ebb16', run_link=None, source='/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow', status='READY', status_message=None, tags={}, user_id=None, version=7>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_id = \"d2aaacb925a14a8b9ca0f66a854ebb16\"\n",
    "model_uri = f\"runs:/{run_id}/models_mlflow\"\n",
    "mlflow.register_model(model_uri=model_uri, name=\"nyc-taxi-regressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version: 7, stage: Production\n",
      "version: 3, stage: Archived\n",
      "version: 6, stage: Staging\n",
      "version: 5, stage: Staging\n",
      "version: 4, stage: None\n",
      "version: 2, stage: None\n",
      "version: 1, stage: None\n"
     ]
    }
   ],
   "source": [
    "model_name = \"nyc-taxi-regressor\"\n",
    "latest_versions = client.search_model_versions(filter_string=f\"name = '{model_name}' \")\n",
    "\n",
    "for version in latest_versions:\n",
    "    print(f\"version: {version.version}, stage: {version.current_stage}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77270/3739034417.py:3: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.13.0/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1717087053211, current_stage='Staging', description=None, last_updated_timestamp=1717087066757, name='nyc-taxi-regressor', run_id='d2aaacb925a14a8b9ca0f66a854ebb16', run_link=None, source='/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow', status='READY', status_message=None, tags={}, user_id=None, version=7>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_version = 7\n",
    "new_stage = \"Staging\"\n",
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=new_stage,\n",
    "    archive_existing_versions=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1717087053211, current_stage='Staging', description='The model version 7 was transitioned to Staging on 2024-05-30', last_updated_timestamp=1717087067806, name='nyc-taxi-regressor', run_id='d2aaacb925a14a8b9ca0f66a854ebb16', run_link=None, source='/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow', status='READY', status_message=None, tags={}, user_id=None, version=7>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "date = datetime.today().date()\n",
    "client.update_model_version(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    description=f\"The model version {model_version} was transitioned to {new_stage} on {date}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing versions and selecting the new \"Production\" model\n",
    "\n",
    "In the last section, we will retrieve models registered in the model registry and compare their performance on an unseen test set. The idea is to simulate the scenario in which a deployment engineer has to interact with the model registry to decide whether to update the model version that is in production or not.\n",
    "\n",
    "These are the steps:\n",
    "\n",
    "1. Load the test dataset, which corresponds to the NYC Green Taxi data from the month of March 2021.\n",
    "2. Download the `DictVectorizer` that was fitted using the training data and saved to MLflow as an artifact, and load it with pickle.\n",
    "3. Preprocess the test set using the `DictVectorizer` so we can properly feed the regressors.\n",
    "4. Make predictions on the test set using the model versions that are currently in the \"Staging\" and \"Production\" stages, and compare their performance.\n",
    "5. Based on the results, update the \"Production\" model version accordingly.\n",
    "\n",
    "\n",
    "**Note: the model registry doesn't actually deploy the model to production when you transition a model to the \"Production\" stage, it just assign a label to that model version. You should complement the registry with some CI/CD code that does the actual deployment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def read_dataframe(filename):\n",
    "    df = pd.read_parquet(filename)\n",
    "\n",
    "    df.lpep_dropoff_datetime = pd.to_datetime(df.lpep_dropoff_datetime)\n",
    "    df.lpep_pickup_datetime = pd.to_datetime(df.lpep_pickup_datetime)\n",
    "\n",
    "    df['duration'] = df.lpep_dropoff_datetime - df.lpep_pickup_datetime\n",
    "    df.duration = df.duration.apply(lambda td: td.total_seconds() / 60)\n",
    "\n",
    "    df = df[(df.duration >= 1) & (df.duration <= 60)]\n",
    "\n",
    "    categorical = ['PULocationID', 'DOLocationID']\n",
    "    df[categorical] = df[categorical].astype(str)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def preprocess(df, dv):\n",
    "    df['PU_DO'] = df['PULocationID'] + '_' + df['DOLocationID']\n",
    "    categorical = ['PU_DO']\n",
    "    numerical = ['trip_distance']\n",
    "    train_dicts = df[categorical + numerical].to_dict(orient='records')\n",
    "    return dv.transform(train_dicts)\n",
    "\n",
    "\n",
    "def test_model(name, stage, X_test, y_test):\n",
    "    model = mlflow.pyfunc.load_model(f\"models:/{name}/{stage}\")\n",
    "    y_pred = model.predict(X_test)\n",
    "    return {\"rmse\": mean_squared_error(y_test, y_pred, squared=False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = read_dataframe(\"data/green_tripdata_2021-03.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "794f2e239e5a42578016f6eabf5af42f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/preprocessor'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.download_artifacts(run_id=run_id, path='preprocessor', dst_path='.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"./preprocessor/preprocessor.b\", \"rb\") as f_in:\n",
    "    dv = pickle.load(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_test = preprocess(df, dv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = \"duration\"\n",
    "y_test = df[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: '/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/7852b56e86ce44e0a8ac2cc920633a93/artifacts/model/.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m<timed eval>:1\u001b[0m\n",
      "Cell \u001b[0;32mIn[11], line 31\u001b[0m, in \u001b[0;36mtest_model\u001b[0;34m(name, stage, X_test, y_test)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_model\u001b[39m(name, stage, X_test, y_test):\n\u001b[0;32m---> 31\u001b[0m     model \u001b[38;5;241m=\u001b[39m mlflow\u001b[38;5;241m.\u001b[39mpyfunc\u001b[38;5;241m.\u001b[39mload_model(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels:/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstage\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrmse\u001b[39m\u001b[38;5;124m\"\u001b[39m: mean_squared_error(y_test, y_pred, squared\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)}\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/pyfunc/__init__.py:940\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_uri, suppress_warnings, dst_path, model_config)\u001b[0m\n\u001b[1;32m    936\u001b[0m         entity_list\u001b[38;5;241m.\u001b[39mappend(Entity(job\u001b[38;5;241m=\u001b[39mjob_entity))\n\u001b[1;32m    938\u001b[0m     lineage_header_info \u001b[38;5;241m=\u001b[39m LineageHeaderInfo(entities\u001b[38;5;241m=\u001b[39mentity_list) \u001b[38;5;28;01mif\u001b[39;00m entity_list \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 940\u001b[0m local_path \u001b[38;5;241m=\u001b[39m _download_artifact_from_uri(\n\u001b[1;32m    941\u001b[0m     artifact_uri\u001b[38;5;241m=\u001b[39mmodel_uri, output_path\u001b[38;5;241m=\u001b[39mdst_path, lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info\n\u001b[1;32m    942\u001b[0m )\n\u001b[1;32m    944\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m suppress_warnings:\n\u001b[1;32m    945\u001b[0m     model_requirements \u001b[38;5;241m=\u001b[39m _get_pip_requirements_from_model_path(local_path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/tracking/artifact_utils.py:111\u001b[0m, in \u001b[0;36m_download_artifact_from_uri\u001b[0;34m(artifact_uri, output_path, lineage_header_info)\u001b[0m\n\u001b[1;32m    108\u001b[0m repo \u001b[38;5;241m=\u001b[39m get_artifact_repository(artifact_uri\u001b[38;5;241m=\u001b[39mroot_uri)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, ModelsArtifactRepository):\n\u001b[0;32m--> 111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    112\u001b[0m         artifact_path\u001b[38;5;241m=\u001b[39martifact_path,\n\u001b[1;32m    113\u001b[0m         dst_path\u001b[38;5;241m=\u001b[39moutput_path,\n\u001b[1;32m    114\u001b[0m         lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info,\n\u001b[1;32m    115\u001b[0m     )\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m repo\u001b[38;5;241m.\u001b[39mdownload_artifacts(artifact_path\u001b[38;5;241m=\u001b[39martifact_path, dst_path\u001b[38;5;241m=\u001b[39moutput_path)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/models_artifact_repo.py:190\u001b[0m, in \u001b[0;36mModelsArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path, lineage_header_info)\u001b[0m\n\u001b[1;32m    186\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo\u001b[38;5;241m.\u001b[39mdownload_artifacts(\n\u001b[1;32m    187\u001b[0m         artifact_path, dst_path, lineage_header_info\u001b[38;5;241m=\u001b[39mlineage_header_info\n\u001b[1;32m    188\u001b[0m     )\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     model_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrepo\u001b[38;5;241m.\u001b[39mdownload_artifacts(artifact_path, dst_path)\n\u001b[1;32m    191\u001b[0m \u001b[38;5;66;03m# NB: only add the registered model metadata iff the artifact path is at the root model\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;66;03m# directory. For individual files or subdirectories within the model directory, do not\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;66;03m# create the metadata file.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(model_path) \u001b[38;5;129;01mand\u001b[39;00m MLMODEL_FILE_NAME \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(model_path):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/mlflow/store/artifact/local_artifact_repo.py:91\u001b[0m, in \u001b[0;36mLocalArtifactRepository.download_artifacts\u001b[0;34m(self, artifact_path, dst_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m local_artifact_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39martifact_dir, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mnormpath(artifact_path))\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(local_artifact_path):\n\u001b[0;32m---> 91\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo such file or directory: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlocal_artifact_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(local_artifact_path)\n",
      "\u001b[0;31mOSError\u001b[0m: No such file or directory: '/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/7852b56e86ce44e0a8ac2cc920633a93/artifacts/model/.'"
     ]
    }
   ],
   "source": [
    "%time test_model(name=model_name, stage=\"Production\", X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/30 18:40:10 INFO mlflow.pyfunc: To install the dependencies that were used to train the model, run the following command: '%pip install -r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.pyfunc.get_model_dependencies(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://aws:****@vizzia-cloudai-dev-domain-060840579676.d.codeartifact.eu-west-3.amazonaws.com/pypi/vizzia-cloudai-dev-repository/simple/\n",
      "Requirement already satisfied: mlflow==2.13.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from -r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.13.0)\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://vizzia-cloudai-dev-domain-060840579676.d.codeartifact.eu-west-3.amazonaws.com/pypi/vizzia-cloudai-dev-repository/simple/numpy/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting numpy==1.26.4 (from -r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 2))\n",
      "  Obtaining dependency information for numpy==1.26.4 from https://files.pythonhosted.org/packages/3a/d0/edc009c27b406c4f9cbc79274d6e46d634d139075492ad055e3d68445925/numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: 401 Error, Credentials not correct for https://vizzia-cloudai-dev-domain-060840579676.d.codeartifact.eu-west-3.amazonaws.com/pypi/vizzia-cloudai-dev-repository/simple/pandas/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandas==2.2.2 (from -r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 3))\n",
      "  Obtaining dependency information for pandas==2.2.2 from https://files.pythonhosted.org/packages/fc/a5/4d82be566f069d7a9a702dcdf6f9106df0e0b042e738043c0cc7ddd7e3f6/pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://vizzia-cloudai-dev-domain-060840579676.d.codeartifact.eu-west-3.amazonaws.com/pypi/vizzia-cloudai-dev-repository/simple/psutil/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting psutil==5.9.8 (from -r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 4))\n",
      "  Obtaining dependency information for psutil==5.9.8 from https://files.pythonhosted.org/packages/c5/4f/0e22aaa246f96d6ac87fe5ebb9c5a693fbe8877f537a1022527c47ca43c5/psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
      "Requirement already satisfied: scikit-learn==1.5.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from -r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 5)) (1.5.0)\n",
      "\u001b[33mWARNING: 401 Error, Credentials not correct for https://vizzia-cloudai-dev-domain-060840579676.d.codeartifact.eu-west-3.amazonaws.com/pypi/vizzia-cloudai-dev-repository/simple/scipy/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scipy==1.13.0 (from -r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 6))\n",
      "  Obtaining dependency information for scipy==1.13.0 from https://files.pythonhosted.org/packages/e8/fb/e5955e2ddbdf2baee461eb53ec8d0adedd20a6dfc5510ef8d5e7e44ba461/scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: 401 Error, Credentials not correct for https://vizzia-cloudai-dev-domain-060840579676.d.codeartifact.eu-west-3.amazonaws.com/pypi/vizzia-cloudai-dev-repository/simple/xgboost/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting xgboost==2.0.3 (from -r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 7))\n",
      "  Obtaining dependency information for xgboost==2.0.3 from https://files.pythonhosted.org/packages/c3/eb/496aa2f5d356af4185f770bc76055307f8d1870e11016b10fd779b21769c/xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata\n",
      "  Downloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: Flask<4 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.2.2)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.13.1)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (5.3.2)\n",
      "Requirement already satisfied: click<9,>=7.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (8.0.4)\n",
      "Requirement already satisfied: cloudpickle<4 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.2.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (7.0.0)\n",
      "Requirement already satisfied: entrypoints<1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (0.4)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.1.43)\n",
      "Requirement already satisfied: graphene<4 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.3)\n",
      "Requirement already satisfied: importlib-metadata!=4.7.0,<8,>=3.7.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (6.0.0)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.4.1)\n",
      "Requirement already satisfied: matplotlib<4 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.7.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.0.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.24.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.0.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.24.0)\n",
      "Requirement already satisfied: packaging<25 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (23.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.12.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (4.25.1)\n",
      "Requirement already satisfied: pyarrow<16,>=4.0.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (11.0.0)\n",
      "Requirement already satisfied: pytz<2025 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2022.7)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (6.0)\n",
      "Requirement already satisfied: querystring-parser<2 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.2.4)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.27.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.4.39)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (0.5.0)\n",
      "Requirement already satisfied: Jinja2<4,>=2.11 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.1.2)\n",
      "Requirement already satisfied: gunicorn<23 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (22.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from pandas==2.2.2->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 3)) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from pandas==2.2.2->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 3)) (2023.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.5.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 5)) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from scikit-learn==1.5.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 5)) (3.5.0)\n",
      "Requirement already satisfied: Mako in /home/arnaud/anaconda3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.3.5)\n",
      "Requirement already satisfied: typing-extensions>=4 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from alembic!=1.10.0,<2->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (4.7.1)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from docker<8,>=4.0.0->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.26.16)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from Flask<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.2.3)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from Flask<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from gitpython<4,>=3.1.9->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (4.0.11)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.2.3)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.2.0)\n",
      "Requirement already satisfied: aniso8601<10,>=8 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from graphene<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (9.0.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from importlib-metadata!=4.7.0,<8,>=3.7.0->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.11.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from Jinja2<4,>=2.11->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.1.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.4.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from matplotlib<4->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.0.9)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from opentelemetry-api<3,>=1.0.0->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.2.14)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from opentelemetry-sdk<3,>=1.0.0->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (0.45b0)\n",
      "Requirement already satisfied: six>=1.5 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas==2.2.2->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 3)) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2023.7.22)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from requests<3,>=2.17.3->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (2.0.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.0.0->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (1.14.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /home/arnaud/anaconda3/lib/python3.11/site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow==2.13.0->-r /home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt (line 1)) (5.0.1)\n",
      "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached psutil-5.9.8-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
      "Downloading scipy-1.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading xgboost-2.0.3-py3-none-manylinux2014_x86_64.whl (297.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m297.1/297.1 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: psutil, numpy, scipy, pandas, xgboost\n",
      "  Attempting uninstall: psutil\n",
      "    Found existing installation: psutil 5.9.0\n",
      "    Uninstalling psutil-5.9.0:\n",
      "      Successfully uninstalled psutil-5.9.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.0.3\n",
      "    Uninstalling pandas-2.0.3:\n",
      "      Successfully uninstalled pandas-2.0.3\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gensim 4.3.0 requires FuzzyTM>=0.4.0, which is not installed.\n",
      "spyder 5.4.3 requires pyqt5<5.16, which is not installed.\n",
      "spyder 5.4.3 requires pyqtwebengine<5.16, which is not installed.\n",
      "tables 3.8.0 requires blosc2~=2.0.0, which is not installed.\n",
      "tables 3.8.0 requires cython>=0.29.21, which is not installed.\n",
      "numba 0.57.0 requires numpy<1.25,>=1.21, but you have numpy 1.26.4 which is incompatible.\n",
      "vizzia-data-analysis 0.0.0.0 requires pandas==2.0.3, but you have pandas 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4 pandas-2.2.2 psutil-5.9.8 scipy-1.13.0 xgboost-2.0.3\n"
     ]
    }
   ],
   "source": [
    "! pip install -r '/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow/requirements.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/05/30 18:42:05 WARNING mlflow.pyfunc: The version of Python that the model was saved in, `Python 3.12.3`, differs from the version of Python that is currently running, `Python 3.11.4`, and may be incompatible\n",
      "/home/arnaud/anaconda3/lib/python3.11/site-packages/xgboost/core.py:160: UserWarning: [18:42:05] WARNING: /workspace/src/objective/regression_obj.cu:209: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 32.4 s, sys: 56.7 ms, total: 32.4 s\n",
      "Wall time: 2.45 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arnaud/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_regression.py:492: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'rmse': 6.2702965482607915}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time test_model(name=model_name, stage=\"Staging\", X_test=X_test, y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_77270/4095759336.py:1: FutureWarning: ``mlflow.tracking.client.MlflowClient.transition_model_version_stage`` is deprecated since 2.9.0. Model registry stages will be removed in a future major release. To learn more about the deprecation of model registry stages, see our migration guide here: https://mlflow.org/docs/2.13.0/model-registry.html#migrating-from-stages\n",
      "  client.transition_model_version_stage(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<ModelVersion: aliases=[], creation_timestamp=1717087053211, current_stage='Production', description='The model version 7 was transitioned to Staging on 2024-05-30', last_updated_timestamp=1717087392425, name='nyc-taxi-regressor', run_id='d2aaacb925a14a8b9ca0f66a854ebb16', run_link=None, source='/home/arnaud/Documents/Github/mlops-camp/02-experiment-tracking/mlruns/1/d2aaacb925a14a8b9ca0f66a854ebb16/artifacts/models_mlflow', status='READY', status_message=None, tags={}, user_id=None, version=7>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.transition_model_version_stage(\n",
    "    name=model_name,\n",
    "    version=model_version,\n",
    "    stage=\"Production\",\n",
    "    archive_existing_versions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0848c9d6c7d415ad6c477ff7ff8e98694d1a4aa96d0deee89244642e6b630036"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
